{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Breast Cancer\n",
    "In this exercise, we'll explore a valuable application of Machine Learning: predicting whether or not tumors are **benign** or **malignant**. We'll use the (real) [Wisconsin Breast Cancer dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.names), that is included in the `sklearn` library. Through this exercise, you'll learn the steps associated with implementing a Machine Learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry \n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
      "        13 is Radius SE, field 23 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Import the dataset from sklearn\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Convert to Pandas dataframe for some exploration\n",
    "data_pd = pd.DataFrame(columns=data.feature_names, data=data.data)\n",
    "data_pd['outcome'] = data.target\n",
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our First Machine Learning Model: A Decision Tree\n",
    "Without doing any pre-processing (or considering the idea of training/testing data), let's try implementing our first machine learning model, a **Decision Tree**. Like any model, it will involve a few steps (to be elaborated upon as we go):\n",
    "\n",
    "- **Import** your model from `sklearn`\n",
    "- **Create** your model with the desired parameters\n",
    "- **Fit** your model to the data\n",
    "- **Assess** performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your model, a decision tree classifier (typically imported at the beginning of your script)\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=11, splitter='best')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a classifier, then fit the model to your data (creating a decision tree)\n",
    "# To ensure consistent results, we can use the random_state parameter\n",
    "tree_clf = DecisionTreeClassifier(random_state = 11)\n",
    "tree_fit = tree_clf.fit(data.data, data.target)\n",
    "tree_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Assess the fit of our data by generating predictions using your data\n",
    "# Then calculate the accuracy (percentage of the time that the predictions equal the data)\n",
    "tree_preds = tree_fit.predict(data.data)\n",
    "acc = (tree_preds == data.target).sum() / len(data.target)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing Data\n",
    "In actual machine learning applications, the intention is to **predict unknown values**. In the example above, you were able to perfectly predict the values because _your model has seen them_. To simulate a _real world_ application, it's necessary to **hide testing data from your model**, and then use your hidden (**test**) data to assess your performance. This can easily be achieved using the `test_train_split` method from `sklearn`. We'll augment our machine learning process to now include splitting our dataset into testing and training data:\n",
    "\n",
    "\n",
    "\n",
    "- **Import** your model\n",
    "- **Create** your model\n",
    "- <span style=\"color:red\">**Split** data into training and testing data</span>\n",
    "- **Fit** your model to **training** data\n",
    "- **Assess** performance of the model on your **test** data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171, 30)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split your data into test and training data with a test size of 30% (.3)\n",
    "from sklearn.model_selection import train_test_split # typically done at the start of the script\n",
    "train_features, test_features, train_outcome, test_outcome = train_test_split(data.data, data.target, test_size=.3, random_state=11)\n",
    "np.shape(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the classifier -- from above -- using our (training) data \n",
    "tree_fit = tree_clf.fit(train_features, train_outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assess the model using our (test) data. \n",
    "# You can import and use the `accuracy_score` fucntion rather than manually computing it\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "tree_preds = tree_fit.predict(test_features)\n",
    "accuracy_score(tree_preds, test_outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not required: use graphviz to visualize your tree\n",
    "# import graphviz\n",
    "from sklearn import tree \n",
    "\n",
    "tree.export_graphviz(tree_clf, feature_names=data.feature_names, class_names=['Benign', 'Malig.'], out_file=\"mytree.dot\")\n",
    "\n",
    "# To conver, you'll need to install graphviz: conda install grahpviz\n",
    "# Then on your terminal: dot -Tpng mytree.dot -o mytree.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Second Model: K-Nearest Neighbors\n",
    "K-Nearest Neighbors is a very simple algorithm. To identify the classification of any observation (row), we simply need to look at the class of K similar points. This introduces two new questions:\n",
    "\n",
    "1. How do we decide on the number of neighbors to use for classifying any given point (K)?\n",
    "2. How do we calculate distance when our features (columns) are in different units?\n",
    "\n",
    "We'll address each of these challenges in the following sections. However, we'll start by simply implementing the algorithm (which will follow the same process as other algorithms). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and create a KNN classifier that uses the 4 nearest points\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to our (training) data, and use it to predict on our *test data*\n",
    "knn_fit = knn_clf.fit(train_features, train_outcome)\n",
    "knn_preds = knn_fit.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9181286549707602"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assess the accuracy of the model\n",
    "accuracy_score(knn_preds, test_outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Picking the number of neighbors (K)\n",
    "In the above section, we arbitrarily used the number **4** for K. We want to use a data driven process for picking this value. Because we **don't look at the test data** until the end, we need another strategy for assessing model parameters. To do this, we can further split the training data into a **validation set** (think of this as a mini-test set), which we can use to search for the best value of **K**. Our process now involves:\n",
    "\n",
    "\n",
    "- **Import** your model\n",
    "- **Create** your model\n",
    "- **Split** data into training and testing data\n",
    "- <span style=\"color:red\">**Split** _training_ data into (smaller) training and **validation** data</span>\n",
    "- **Fit** your model to (smaller) **training** data\n",
    "- <span style=\"color:red\">**Assess** performance of the model on your **validation** data to tweak parameters</span>\n",
    "- **Assess** performance of the model on your **test** data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's crete a validation set by sampling 20% (.2) out of the *training* data\n",
    "# We can use the `train_test_set` function as before\n",
    "train_features_small, validation_features, train_outcome_small, validation_outcome = train_test_split(train_features, train_outcome, test_size=.2, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0.9,\n",
       " 2: 0.925,\n",
       " 3: 0.9125,\n",
       " 4: 0.925,\n",
       " 5: 0.925,\n",
       " 6: 0.9375,\n",
       " 7: 0.9375,\n",
       " 8: 0.925,\n",
       " 9: 0.925}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's assess accuracies of K from 1 through 10. To do this, loop through values of K, \n",
    "# and in each loop:\n",
    "# - Create a new classifier using K as the number of neighbors, \n",
    "# - Fit the classifier to the (small) training data (without validation data)\n",
    "# - Generate a set of predictions using the validation data\n",
    "# - Compute the accuracy of your model on your validation data\n",
    "accuracies = {}\n",
    "for k in np.arange(1, 10):\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn_fit = knn_clf.fit(train_features_small, train_outcome_small)\n",
    "    knn_preds = knn_fit.predict(validation_features)\n",
    "    accuracies[k] = accuracy_score(knn_preds, validation_outcome)\n",
    "    \n",
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9298245614035088"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that you know the best value of K based on your *validation* data, \n",
    "# Run the KNN with the optimal value of K on the *test* data to assess your performance\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=6)\n",
    "knn_fit = knn_clf.fit(train_features_small, train_outcome_small)\n",
    "knn_preds = knn_fit.predict(test_features)\n",
    "accuracy_score(knn_preds, test_outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "In the above example, we created a **single** validation dataset from our training data. However, because this sampling is **random**, we may have gotten a certain subset of the training set simply **by chance**. The most popular strategy for solving this issue (and therefore better leveraging the information in our _training data_) is called **cross validation**. \n",
    "\n",
    "There are a number of strategies for cross-validation, but the philosophy is the same: split the training data into a (smaller) training and a validation set **multiple times**. For example, a popular approach is the **K Fold** cross validation which splits the data into **K** folds (_not_ to be confused with the **K** from **KNN**). Then, each _fold_ of the data is used as the validation set one time. This allows each observation to appear in the validation set one time. You then assess model performance for each fold, and pick your best model based on the **average** performance across the folds. \n",
    "\n",
    "Luckily, the `sklearn` toolkit has a variety of built-in methods for performing this process. This is really only a minor change to our process:\n",
    "\n",
    "- **Import** your model\n",
    "- **Create** your model\n",
    "- **Split** data into training and testing data\n",
    "- <span style=\"text-decoration:line-through\">**Split** _training_ data into (smaller) training and **validation** data</span> (accomplished in new step below)\n",
    "- <span style=\"color:red\">**Fit** and **assess** your model using `cross_val_score` to fit the model on different _folds_ of validation data</span>\n",
    "- <span style=\"text-decoration:line-through\">**Assess** performance of the model on your **validation** data to tweak parameters</span> (accomplished in new step above)\n",
    "- **Assess** performance of the model on your **test** data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9       , 0.975     , 0.95      , 0.925     , 0.95      ,\n",
       "       0.9       , 0.925     , 0.875     , 0.84615385, 0.94871795])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use cross validation (`cross_val_score`) to test a classifier across 10 different splits of the data\n",
    "# Use a K value of 3 for your KNN.\n",
    "# Notice the huge variation in performance across folds!\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(KNeighborsClassifier(3), train_features, train_outcome, cv=KFold(n_splits=10, shuffle=True, random_state=11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "Unfortunately, the above code only runs a **single model** across **K** different _folds_ of the data. What we really want to do is iterate over our parameter space (the number of different **neighbors**) for each of the folds. While this would be simple enough to write as a loop, we can easily use the **grid search** functionality built into the `sklearn` toolkit. The benefit is that grid search will seach over a _grid_ of **all parameters** of interest regarding your model (while we only have one current parameter to optimize, we could have many). This will allow you to quickly identify the optimal set of parameters for your model. \n",
    "\n",
    "\n",
    "- **Import** your model\n",
    "- **Create** your model\n",
    "- **Split** data into training and testing data\n",
    "- <span style=\"text-decoration:line-through\">**Fit** and **assess** your model using `cross_val_score` to fit the model on different _folds_ of validation data</span>\n",
    "- <span style=\"color:red\">**Fit** and **assess** models using `grid_search` to fit multiple models using **different parameters** on different _folds_ of validation data</span>\n",
    "- <span style=\"text-decoration:line-through\">**Assess** performance of the model on your **validation** data to tweak parameters</span> (accomplished in new step above)\n",
    "- **Assess** performance of the (best) model on your **test** data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the `GridSearchCV` model, and specify a grid of parameters\n",
    "# This will try all possible combination of parameters in a brute force way\n",
    "# And, it will run cross validation on each combination of parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_neighbors': np.arange(1, 50)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a grid search estimator for your KNN classifier\n",
    "# When fit, this will search the parameter grid using cross validation\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(), param_grid, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the grid search to your training data\n",
    "grid_search.fit(train_features, train_outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9181286549707602"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict and assess performance on your **test** data\n",
    "grid_search.score(test_features, test_outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEGCAYAAACtqQjWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOy9eZwddZX3/z699+393u6EJN3ZOlEJSABDIA0K4gaOioij4IyjDg7POPJzHh3np4yKI48+jMq4ojMPOrjPoCIqCsqjEUbMAknYBFnS3QnpTkKS3ju9L+f5o6puqm/fpbr7Vq/n/XrdV1d9q75V30q669zzPef7OaKqGIZhGEY2yJnrARiGYRiLBzMqhmEYRtYwo2IYhmFkDTMqhmEYRtYwo2IYhmFkjby5HsBcUl1drWvXrp3rYRiGYSwo9u3b16aqNcmOLWmjsnbtWvbu3TvXwzAMw1hQiMjzqY7Z9JdhGIaRNUI1KiJymYg8KyKNIvLRJMfXiMh2EXlCRB4QkVq3/WwR2SUiT7nH3u7r86CIPOZ+jojIz9z2S0Sk23fsxjCfzTAMw5hMaNNfIpILfA14DdAK7BGRu1X1T77TbgG+q6rfEZFLgZuBdwL9wF+p6n4RWQnsE5H7VLVLVV/uu8dPgJ/7rvegqr4hrGcyDMMw0hOmp7IVaFTVZlUdBu4Arkg4ZxOw3d2+3zuuqs+p6n53+whwHJgQFBKRMuBS4GehPYFhGIYxJcI0KquAFt9+q9vm53HgKnf7SqBMRGL+E0RkK1AANCX0vRLYrqo9vrZtIvK4iPxKRM5INigRuU5E9orI3hMnTkztiQzDMIy0hGlUJElbonrlh4GLReRR4GLgMDAav4DICuB7wHtUdTyh7zXAf/n2HwHWqOpm4Kuk8GBU9TZV3aKqW2pqkmbEGYZhGNMkTKPSCtT59muBI/4TVPWIqr5FVc8BPua2dQOISDlwD/BxVd3t7+d6M1vd4961elT1pLt9L5AvItVZfyrDMAwjJWGuU9kDbBSRdTgeyNXAO/wnuC/9DtcLuQG43W0vAH6KE8T/cZJr/znwS1Ud9F3rNOCYqqo7ZZYDtGf/sYztTx9jfU0p66pLQr/XyNg4J3qHONYzyPHeIY73DNLZP0JlJJ9lZYUsKy9iWVkhNWWFFOblhj4ewzDSE5pRUdVREbkeuA/IBW5X1adE5CZgr6reDVwC3CwiCvweeL/b/W3AK4CYiLzbbXu3qj7mbl8N/EvCLd8KvE9ERoEB4Gq1YjFZp29olL/9/j5es2k5X/+Ll4V2n7seaeUz9zxNe99w4D5VkXwiBcl/pV+0vJTb330eIslmZQ3DyBahrqh3p6HuTWi70bd9J3Bnkn7fB76f5rqXJGm7Fbh1BsM1AvDwwQ5GxpRdTe2Mjys5OeG8pO/Y00JRfi7/89UbWe56I97PykgB3QMjHOsZ5ETvEMd7BznW4/wcHEkMvcHhzgHuf/YEzW191NeUhjJewzAclrRMizF1duxvA6Czf4SnX+jhjJUVWb9H39Aojx7q5NqL1vM/X/2ipOfUuFNeQTjY1scltzzAzqZ2MyqGETIm02JMiT80trFxmfNi3tUUTsjq4QOON3TRhuzkWayJRVhZUcSuprasXM8wjNSYUTECc6J3iGde6OXKc1exvrqEnSEZlT80tlGQl8OWtVVZuZ6IsK2+Oj5lZxhGeJhRMQKz0/2mf9GGarbVx3iouZ2RsckxjJmyo7GN89ZWUZSfvWyuCzfE4lN2hmGEhxkVIzB/2N9GRXE+Z6ysoKG+mr7hMZ5o7c7qPY73DvLMC71cmKWpL49t9Y5QQ1hTdoZhOJhRMQKhquxobKOhPkZujvhe0tmNU3gv/WzFUzxWVBSzvrqEHY0WVzGMMDGjYgTiQFsfR7oH4x5EtKSA01eUs6Mxu9/8/d5QtmnYEHOTALI/ZWcYhoMZFSMQ3jd8vwfRUB9j36FOBkfGsnIPzxu6cIPjDWWbsKbsDMM4hRkVIxB/aGxjVWUxa2KReNuFG2IMj47zyPOdWblHojeUbS5Y70zZ7bQpMMMIDTMqRkbGxpWdTe1ctKF6gszJeWuj5OYIO7IUV0nmDWWTaEkBm1aUh5YKbRiGGRUjAH883E3v4CgXbZz4si8ryues2oqsvaT/0NhGbVUxq6ORzCdPk2xP2RmGMREzKkZGPA+ioT426diF9dU80dpN7+DIjO6RyhvKNg3ulN2+LE3ZGYYxETMqRkb+sL+NTSvKiZVO1tpqqI8xNq48fKBjRvfwvKGw4ikeW9c5SQA7TbLFMELBjIqRloHhMfY93zlp6svj3DVVFOTlzHgKLJ03lE1KC/PYnMUpO8MwJpLRqIjIhSJS4m7/pYh8QUTWhD80Yz6w52AHw2PjKT2IovxctqypmvFLOp03lG0asjRlZxjGZIJ4Kv8G9IvIZuD/B54HvhvqqIx5w47GNgpyczgvjbhjQ32Mp4/20H5yaFr3yOQNZZuGDdmZsjMMYzJBjMqoW0HxCuDLqvploCzIxUXkMhF5VkQaReSjSY6vEZHtIvKEiDwgIrVu+9kisktEnnKPvd3X59sickBEHnM/Z7vtIiJfce/1hIicG2SMRnr+0NjGuWsqU1ZUBNhW7xiD3c3Te0k/nMEbyjbnrs7OlJ1hGJMJYlR6ReQG4C+Be0QkF8jP1Mk972vA5cAm4BoR2ZRw2i04dejPAm4Cbnbb+4G/UtUzgMuAL4lIpa/fP6rq2e7HKzF8ObDR/VyH42EZM6Cjb5injvRkXDeyubaC0sK8aQe/g3hD2cSbsjMdMMPIPkGMytuBIeBaVX0BWAV8PkC/rUCjqjar6jBwB46342cTsN3dvt87rqrPqep+d/sIcByoyXC/K3AMlKrqbqBSRFYEGKeRAu+lm8mDyMvNYeu66LS/+f9hf2ZvKNtcuKGaZ17onfaUnWEYycloVFT1BVX9gqo+6O4fUtUgMZVVQItvv9Vt8/M4cJW7fSVQJiIT0n9EZCtQADT5mj/jTnF9UUS8yG6Q+yEi14nIXhHZe+LEiQCPsXTZ0dhGWVEeL12VWdyxoT7myKx0DUzpHu0nh/jT0czeULbxVJanO2VnGEZyUhoVEekVkZ5UnwDXTraCLbHs3oeBi0XkUeBi4DAw6hvDCuB7wHtU1ZOWvQF4CXAeEAU+MoX7oaq3qeoWVd1SU5PJ+Vm6qCoP7m9j2/oYebmZHdoGN64y1Xolnndz0cbZ/b84a5UzZZctiRnDMBxSzjeoahmAiNwEvIDzchfgLwgWqG8F6nz7tcCRhHscAd7i3qcUuEpVu939cuAe4OPudJbX56i7OSQi38IxTIHuZySnq3+YYz1DHOsZ5HjvEMd7BzncOcDhrgH+x8XrA13jJaeVURXJZ0dTG1e9rDbwvafiDWWTvNwczl8XtaJdhpFlgkxiv05Vz/ft/5uIPAR8LkO/PcBGEVmH44FcDbzDf4KIVAMdrhdyA3C7214A/BQnRvLjhD4rVPWoOFoebwaedA/dDVwvIncA5wPdPgNkpOAr2/fzhd88N6m9rDCP01eU89pNpwW6To5buOuhKU4n7WpuZ9v6cKTuM7GtPsb2Z47zzQebs1K6WARiJQXUlBWxrKyQZeWFFOZlrySyYSwEghiVMRH5C5xAuwLXABnV+FR1VESuB+4DcoHbVfUp1/PZq6p3A5cAN4uIAr8H3u92fxvwCiAmIu92297tZnr9QERqcLymx4C/dY/fC7weaMTJHntPgGdb8ux7vpO6aDEfuewlLCsrYnl5IcvKiigumPrL8MXLy7n3jy8wODIW6CU9PDpOS0c/V5w9KfQ1K7zyJcu4+VfP8Ol7ng7tHpWRfJaXFREpTP7vsa66hH/9882h6p0ZxmwSxKi8A/iy+1FgBwkeRypU9V6cl72/7Ubf9p3AnUn6fR/4foprXpqiXTlllIyAtHT089JVFbzhrJUzvlZtVTEAR7oGWF9TmvH8F7oHGddT/Wab+ppSHr3xNVlTLB4fh/a+IY73OFOIx3uGOOb+HEhyjyNdA9z1yGH++U1nUF6UMUvfMBYEGY2Kqh5kciqwsQgYH1daOwd4zRnLs3K9OleyvqUzmFFp6ex3+lWFJ3WfifKi/Ky+0E+rKOKMgPb5rkda+dCPHqf95LAZFWPRkNKoiMhXSZI95aGqHwhlRMascax3kOGx8ay91D2Po9U1FpnwzpsrT2Wu8XTO2k8Osa66ZI5HYxjZIZ2nsnfWRmHMCYfanZd6topiLS8vIj9XaO0MtlaltXOA3BxhRUVRVu6/0IiVFADQdnJ4jkdiGNkjXUrxd/z7IlLmNOvJ0EdlzAot7su/LktGJTdHWFlZTEtHME+lpaOfFRVFgdbBLEaqPU+lz1b1G4uHINL3Z7qLE58E/iQi+0TkjPCHZoTNoY5+RGBVZfamn2qriqfkqSzVqS+AqOuptJunYiwignxFvA34kKquUdXVwD8A3wh3WMZs0NrRz8qKYgrysucp1FZGpmhU5i5IP9cU5OVQXpRn+mPGoiLI26REVe/3dlT1AcCiiouAQx39WfcU6qLFtJ0cypimOzQ6xrHewSXtqYAzBdbWZ56KsXgIYlSaReQTIrLW/XwcOBD2wIzwOdTRn7UgvYfneWTKADvSNYjq3KYTzwdipQW09ZqnYiweghiVv8aRnb/L/VRjq9UXPIMjYxzvHQrBqDieR0uGKbClnk7sESsppN08FWMRkW6dyvdU9Z04xbJsTcoiw3upZyvzy8O7Xqa4SkuHc7w2y/dfaFSXFfDQAfNUjMVDOk/lZSKyBvhrEakSkaj/M1sDNMLBe6ln26jUlBZSkJtDa4a04tbOfvJyhNPKl+YaFY9YSSGd/SOMjo1nPtkwFgDpFj/+O/BrYD2wj4n1StRtNxYohzo8TyW70085OcKqAGnFrZ0DrKwsnhN14vlEdamTVtzRP8yysqVtYI3FQUpPRVW/oqqn46gLr1fVdb6PGZQFzqGOforyc6gpLcx88hRx1qqk91RaOrOfebYQOSXVYnEVY3EQpJzw+2ZjIMbs0uJmfoUhuV5bFQkQqB9Y8plfcEqqxYyKsVhYmvoYBoc6+kN7qddWFdPRN0zf0GjS44MjY5zoHTJPBZ+nYlItxiIhVKMiIpeJyLMi0igiH01yfI2IbBeRJ0TkARGpddvPFpFdIvKUe+ztvj4/cK/5pIjcLiL5bvslItItIo+5nxsT72c4qDqS99kO0nt41z3cldxb8eIttVmO5yxEvJiKiUoai4WURkVEbhWRhuleWERyga8BlwObgGtEZFPCabfglAw+C7gJuNlt78dJZT4DuAz4kohUusd+ALwEeClQDLzXd70HVfVs93PTdMe+2OnsH+Hk0GhoRiW+ViVFBljrPKijMl8oL8onL0dMqsVYNKTzVPYD/yoiB0XksyJy9hSvvRVoVNVmVR3GKUecWOxrE7Dd3b7fO66qz6nqfnf7CHAcZwEmqnqvugAPA7VTHNeSx8v8yvbCR49TdVUyeCpmVMjJEaIlBbSZUTEWCemyv76sqtuAi4EO4Fsi8rSI3CgiLwpw7VVAi2+/1W3z8zhwlbt9JVAmIjH/CSKyFSgAmhLa84F34qQ9e2wTkcdF5FeplJRF5DoR2Ssie0+cOBHgMRYfLSEblZrSQgrzclJmgLV09lOQm8Oysuxnni1EqksLLVBvLBqCZH89r6qfVdVzcGrTXwk8HeDaydKKEitJfhi42JXWvxg4DMSjuyKyAvge8B5VTVwd9nXg96r6oLv/CLBGVTcDXwV+luJ5blPVLaq6paamJsBjLD48TyWsQLmIUFtVHF9gmUhr5wCrqorJWeJrVDxipQUmKmksGoLUU8kXkTeKyA+AXwHPccq7SEcrUOfbrwWO+E9Q1SOq+hbXYH3Mbet271sO3AN8XFV3J4zpkzjTYR/yXavHKyCmqvcC+SJSHWCcC4rBkTEOtffT3T8y7Wu0dvZTXVpASWG6ta8zoy4aobUrVUxladdRScTxVGz6y1gcpNP+eg1wDfBnOLGLO4DrVLUv4LX3ABtFZB2OB3I1jqfjv0c10OF6ITcAt7vtBcBPcYL4P07o817gdcCr/N6LiJwGHFNVdafMcoD2gGOdEk8e7uZHe1v40GteRGWkIIxbAPCfDx1iz8EOjvcOcqxniOM9g/QMOo7ci5eXcd8HXzGt6zqS9+HGM2qrinmspSvpsdaOfl57xvJQ77+QiJUU2PSXsWhI56n8E7ALOF1V36iqP5iCQUFVR4Hrgftwpst+pKpPichNIvIm97RLgGdF5DlgOfAZt/1twCuAd/tShL1EgX93z92VkDr8VuBJEXkc+ApwtRvMzzovdA/y3V3Pc6At8D/HlBkfVz7x8ye5/9njDAyPsaGmlDefs4p/fN2LefXpy2g8cXLaelFhSN4nUlsVoat/hN7BiR5V//Ao7X3DFqT3ESstZGBkjP7h5Ot6DGMhkW7+4yNATFU7/I2uQTisqvsyXdydhro3oe1G3/adwJ1J+n0f+H6KayYds6reCtyaaUzZwEvFbekc4JzVVaHco294lLFx5fpXbuC9L5+oivPDPYf47dPHOdo9OOW04NGxcY50DXLF5nBf6nVVp9SKT1+RH28/lfll018esdJTq+oj0fCmJA1jNkjnqXyO5AH5PwGfD2c4C4NM6zCyQfeA8w2/vCh/0jHvW35LBn2tZBztHmRsXLMuJJlIqrTiU3VUzFPxOLUA0uIqxsInnVGJqerBxEZVbQRik09fOpQU5hErKcgomjgTegacqZDy4slGJe4FpMiuSkdLRzh1VBJJZXg9IxO2UVtIxEpMVNJYPKQzKun+6pd8jfraaCSemhsGcU+lePJ0yIrKInJkep5KXPI+ZE8hWlJApCB3kqfS0tFPYV446sgLlZh5KsYiIp1R+a2IfEYSZGxF5FPA78Id1vxndTSSch1GNugZTD39lZ+bw4qKzDVLknGowymOtaIi3Nod3lqVRG/OW6MShjryQqU6Lippnoqx8ElnVP4BpxBXo4j8xP00Ai/Gtz5kqVJXVcyRrgHGxkNJMKPH9VQqkkx/Ae7iwql7Ki3uSz0vN3yB6mQS+CZ5P5mi/FxKC/PMUzEWBSlTTdz04WtEZD3gSZ48parNszKyeU5dNMLouHK0eyCUoPOp6a/kRqUuGuHB/VOXmQlT8j6Ruqpi9hyckDxIS2c/Z9VWzMr9FxKxUlurYiwOgsi0NKvqL9yPGRQX78Uc1hRYz+AoIlCWYtV7XVWEYz1DDI6MTem6rR39oQfpPWqrIvQOjsYNZO/gCF39I5b5lYRYSYHVVDEWBVaka5p42UvTCZYHoWdghLLCvJT6WN79j6SoWZKMk0POwsPZyrw6lVbs/Bt59VUs82syMROVNBYJZlSmycrKYicDK6QMsJ6BESoiyae+wL9WJbhRCVudOJH4IlHXm/N+mqcymerSAivUZSwKgghK1otIobt9iYh8wFcwa8niZWCFZVS6B0aSZn55xD2lKdx/to1KoqdyauGjeSqJxEoK6egbYjykxA/DmC2CeCo/AcZEZAPwH8A64D9DHdUCoS5aPCVPYSr0DI6kzPwCWF5WRH6uTGn6bbbWqHhUFOdTWpgXT31u7RygOD+XWEl4IpwLlVhpAeMKXQPTV582jPlAEKMy7opDXgl8SVU/CKwId1gLg7qqyJx5Kjk5wqrKqa1Vae0coKwwj8o002rZJHGtSktHP7W2RiUpMXetiqUVGwudIEZlRESuAd4F/NJtm5230jynLhrheO/UM7CC0DMwmtZT8e7fOgWjdqijn9poZFZf6rVVkQmeik19Jcf0v4zFQhCj8h5gG/AZVT3g1kdJqiC81PDiGtNZ2Z6J7oGRpBItfpItLkyHI3k/uy91x1MZQFVp7Qy/jstCJb6q3oL1xgInyDqVP6nqB1T1v0SkCihT1X+ZhbHNe06tVcnuFNjw6DgDI2MBPJViOvqG6RvKXIdDVWmZhToqidRFI5wcGuVQRz89g6OWTpwCL85kFSCNhU6Q7K8HRKRcRKLA48C3ROQL4Q9t/rM6On0J+nTEdb8yGJVaX82STJzoHWJodHzWFj56eNNdu5vb3X3zVJJRGSkgR0z/y1j4BJn+qlDVHuAtwLdU9WXAq4NcXEQuE5FnRaRRRD6a5PgaEdkuIk+4xqvWbT9bRHaJyFPusbf7+qwTkYdEZL+I/NAtPYyIFLr7je7xtUHGOBNqygopzMvJuqeSSffLo24KdV08wzd3RqVjwr4xkdwcIVpia1WMhU8Qo5InIitwSvz+MtPJHiKSC3wNuBzYhKMjtinhtFtw6tCfBdwE3Oy29wN/papnAJcBX/Ktjfks8EVV3Qh0Ate67dcCnaq6Afiie16oeNlN2ZZqSVegy0/dFDyl2U4n9vA8k11N7XNy/4VErKTQpr+MBU8Qo3ITTp35JlXd4wpM7g/QbyvQ6GqHDQN3AFcknLMJ2O5u3+8dV9XnVHW/u30EOA7UuDL8l3KqBPF3gDe721e4+7jHX5Uo2x8GddFICNNfqQt0+YmVFFCcnxvIqB1qn5syvhXF+ZQX5fFCzyAlBbmzls68EImVFtj0l7HgCRKo/7GqnqWq73P3m1X1qgDXXgW0+PZb3TY/jwPeta4EykRkQlVJEdkKFABNOBUnu9x1M4nXjN/PPd5NkgqVInKdiOwVkb0nTkxd5TeRMNaqdMenv9Jnf6WqWZKMls5+Tisvoig/NytjnAqet1JbNbvpzAsNR//LPBVjYRMkUF8rIj8VkeMicsytq1Ib4NrJ3h6JGhQfBi4WkUeBi4HDQDyVyZ12+x7wHlUdz3DNIPdDVW9T1S2quqWmpibzU2SgLlpMz+Ao3f3ZWwndk0H2fuL9g6UVH+ron7PMK+++lvmVnliJyd8bC58g01/fAu4GVuJ4A79w2zLRCtT59muBI/4TVPWIqr5FVc8BPua2dQOISDlwD/BxVd3tdmkDKkUkL8k14/dzj1cAE4t5hEAYGWBBYyrgBOtbO/pRTa8ZNZuS94n4PRUjNdWlBfQOjYaymNYwZosgRqVGVb+lqqPu59tAkK/4e4CNbrZWAXA1jnGKIyLVIuKN4Qbgdre9APgpThD/x9756rw57wfe6ja9C/i5u323u497/Hea6U2bBWpDWKvSMzhCYV5OoKmqumiE3qFTNUuScbx3kCPdg7xoeVnWxjgVvDiOZX6lx8oKp+fk0Cj/96kXptTnuWO9PHm4O6QRGckIYlTaROQvRSTX/fwl0J6pkxvXuB4nyP808CNVfUpEbhKRN7mnXQI8KyLPAcuBz7jtbwNeAbxbRB5zP2e7xz4CfMgtbRzDEbnE/Rlz2z8ETEphDoOpZGAFpWdgJNDUF/iVgFNPgXnpvNvWTwoxzQp15qkEIhZfVT/1uMqupnbe/4NHQitvPR+4c28L131v35S+wH3y50/xkZ88EeKojETSR4Id/hq4FSdNV4GdbltGVPVe4N6Etht923dyKpPLf873SSEF41af3JqkfRD48yDjyiZedlM204qD6H55+D2lM1clL9O7u7md0sI8zlhZnrUxToVt9TGuvWgdF22snpP7LxRipd6q+ql7Kv/18CHu+eNRrnvFejbXLc7KFAfbHWNyaApTuc+399EzOIqqWpLILJHWqLhrTa5S1TelO2+pk+204p7BEcqLgtj7YJ7S7qZ2tq6Lkpc7NzXZSgrz+MQbEpcoGYlUl0xPqVhV2emuA9rZ1L5ojYpf7ToIw6PjHO0ZRBW6+keospILs0Lat4yqjjF5bYmRQLbTirunMP1VUZxPWRpP6VjPIM1tfXM29WUEJ+6pTDGm0nj8ZNwQ7Wxqy/q45gve7/ihgH9rh7sG8KKqYZX9NiYT5KvrDhG5VUReLiLnep/QR7aAWB1z0nqzVbWvZyB9ga5E6qoiKdeqeJpbF5hRmfdECnIpys+ZckxlR6NjSF59+jL2HOxgaHTxZY+patyYBFXm9n/RC2qIjJkTZI6lwf15k69NcVa2GzhpvcOj45w4OcTy8qIZXy9Tga5J948W03SiL+mxXU3tlBflsWmO4ilGcETElWqZmqeys6mdumgxb9tSx2+fPs5jh7o4f5F9iWjvG2bATbUOOivg906yLaVkpCajUVHVV87GQBYytdFTwfKZGhVVpWcweKAeHE/lv587kTQYuau5na3rYuTmWJByIVBdWkDbFKa/xsaV3c3tXH7mCs5fHyNHHCOz2IyKZ0iqSwsDKUg4fQbIzxUiBXk2/TWLBFlR/799Yo6ISJWIfDrcYS0s4nVVsvCL2zc8xti4ZizQ5ae2qpjBEcdT8nOka4Dn2/u5YH10xuMyZodYaSFtvcGnv5460k3P4CgNG2JUFOfz0lUVizKu4k15XbghRtvJYfqHM9cQanGLwq2JhVf225hMkJjK5ara5e2oaifw+vCGtPCojUvQz9zFDip778fLAEtcq+LFU7bVL65vrYuZ6tIC2vuCGxUv68v7P95WX82jh7oCvXQXEp5RaHCfM0gNodaOfmqrit2Yo01/zRZBjEquiBR6OyJSDBSmOX/JUZSfy7Kywqx8G5qKRItHXTT5qv7dze1UFOdz+mkWT1koOKKSwxlldzx2NrWzcVkpy8qcadeG+hij48qeg51hDnPWae3sJ1ZSEFeFONQerNxDXTRCbbSYw50Di3ph6HwiiFH5PrBdRK4Vkb8GfsMpiXnDZXU0kpUMk+l4KqlW1e9qbuf8dVFyLJ6yYIiVFDA6rvQMZPY0hkfH2XOgI/7tHeC8tVHyc2XRTYEd6uinNhoJrGBxcmiUzv4R6qoi1FVFGB4b51jP4GwMdckTRPr+czjyKacDZwD/y20zfNRFs+Nid09BodgjUpBHrKRggqfS2tlPS8eATX0tMDz9r7YAU2CPtXQxMDJGw4ZTSgXFBbmcs7qKnY0ZlZQWFC0dA9RVFQeuIeT9LdRFi1N68kY4BFpiraq/UtUPq+o/qOp9YQ9qIVJXVczR7gFGxsZndB2vQNdUPBVwMtD8Ri2u92VGZUExFamWnU1tiMAF6yb+HzfUx3jySHdWyzHMJWPjypGuAeqiTj2eumhxRk+lxVfpNF522+Iqs0KQ7K8LRGSPiJwUkdaU43oAACAASURBVGERGRORntkY3EKiNhphXJ2Mq5kwnZgKOEbN/4e2q6mdqkg+L1o2N8rExvSIlQQXldzZ2M6ZKyuoSKimeeGGalRh94HF4a0c7R5gdFzjZSaCKFh4BmR1NMKqqmJEzFOZLYJ4KrcC1+CUEC4G3gt8NcxBLUTiacUzzADrGRhBBMoCan/F7x+NcKTLCUaqOmsXLlgfs3jKAqPa9VQyrVXpHx7l0ZZOGjZM9kQ311ZSnJ/LzsbFEVfx/qa8vzFvqjldMkNLRz+lhXlURvIpzMvltPIiW6sySwSd/moEclV1TFW/BdiCyAS8qoYz/cXtHhihtDBvysagtqqYkTHlhZ5BWjsHONxl8ZSFiCd6mMlT2Xuwk5ExpaF+svJzQV4O562LxtONFzre39SpCqKReCA+ZR83ndhbDFxXFaHVVtXPCkGMSr9bNOsxEfmciHwQKAl5XAuOFRXF5OXIjF3snsGp6X55eN/iWjv62dVkel8LlfzcHCoj+RmVinc0tZGXI5y3tirp8QvrY+w/fpLjvQs/46m1o58cgZWVrlGJrwtL/bfW0jlRHr82QBzGyA5BjMo73fOuB/pwSvZeFeTiInKZiDwrIo0iMqloloisEZHtIvKEiDwgIrW+Y78WkS4R+WVCnwd9hbuOiMjP3PZLRKTbd+zGxPuFSW6OsKqqeMZpxT1T1P3yOJVqOcCu5naqSwvYuKx0RmMx5obq0sz6X7ua2jlndSWRguTTpJ4Hs2sReCuHOvpZUVFMvlu6IVNasaq62WKnjEpdVYQXegYXpdjmfCNISvHzqjqoqj2q+ilV/ZA7HZYWtxbL14DLgU3ANSKSWFTjFpySwWfhCFbe7Dv2eRyDljiel6vq2ap6NrALuMt3+EHvmKrelNg3bOqqIjPOMJlKgS4/KyuL4sHI3c2O9pMVJVqYxEoK0hqV7v4RnjzcnXTqy2PTynLKi/IWRWpxS+fAhFLUp1KEk/+teeKT3nSZ10cVDlsGWOiEWbVpK9Coqs2qOgzcweTaLJuA7e72/f7jqrod6E11cREpw1FK/lk2Bz0T6qLFtM7QU3FqqUwtSA9QmJfL8rIidjS2cbR70Ka+FjDVpYVp16k8dKCdcWXCosdEcnOEbfUxdjYv/GB9S0d/PPMLoLQwj6pIfkpPxZsW8/dZ7fPkjXAJ06isAlp8+61um5/HOTWVdiVQJiJB34ZXAttV1Z/evE1EHheRX4nIGck6ich1IrJXRPaeOHEi4K2CUVsVob1vmL6h6esuTTemAo5R2/u8I89hRbkWLrHS9J7KzqZ2ivJzOHt1+gqPDfXVtHQMLOhU2sGRMY73Dk0qH1wXTZ1W7BkOf594Is0C/rdYKARZp3LmNK+dbO4lMQfww8DFIvIocDFwGAj6Rr4G+C/f/iPAGlXdjJPynNSDUdXbVHWLqm6pqakJeKtgpBJ2nApTraUy4f7uHHJNWSH1NZZLsVCJlRTSPTDC8GjyhbQ7m9o4b22UwrzctNe50E03XsiSLa1xA1E8oT2tUXHb/VNmy8uKKMjNsWD9LBDEU/l3EXlYRP7OL4EfgFacoL5HLXDEf4KqHlHVt6jqOcDH3LbuTBd2vZmtwD2+a/Wo6kl3+14gX0RSTzqHwOoZykGMjI3TPzw2bU/F+yO6wOIpCxpvVX1n/2Rv5UTvEM8dO5k2nuJRX1NKTVnhgk4tjqcTVyV4KlURDnclF4ls6einurRgQhJDjptIY2nF4ROkSNdFIrIR+Gtgr4g8DHxLVX+ToeseYKOIrMPxQK4G3uE/wX3pd6jqOHADcHvAcf858EtVjedLishpwDFVVRHZimMwZ/WvyUt1/N7u5znQ1sey8kKWlRWxvLyQZeVFlBam/+fudSVapqL75ccrFmZTXwub+ALIJJVEPa8jXTzFQ0RoqI+xs6k9aQG3hcApDa/E6S9nXdaxnsF4qnG8j1tHJZHaLGRnGpkJFBFW1f0i8nFgL/AV4BxxfkP/SVXvStFnVESuB+4DcoHbVfUpEbkJ2KuqdwOXADeLiAK/B97v9ReRB4GXAKUi0gpc69Mduxr4l4RbvhV4n4iMAgPA1RpUPzxLREsKaKiPsbu5nf9+bnK85tWnL+Ob7zovZf/uaSgU+9m2Psa5qyt59enLptXfmB/EXFHJe544yv5jJyccu+vRw5QV5XHmqopA17qwvpqfP3aExuMn2bh85pI9+57v4MxVFRmn3rJFS0c/BXk51JROrLZxSsGif7JR6Rhgc93kSZW6aIQ/Hj4a3mANIIBREZGzgPcAf4Yje/9GVX1ERFYyOaV3Au401L0JbTf6tu8E7kzR9+VprntJkrZbcSRl5gwR4T//5gKnJPDAKMd7BzneO8Tx3kHu3Nea8RtjT1yheOrZX+D80dz1dxdOe/zG/GB1NEJujvD1B5qSHn/DWSsCl4feus6p+rnv+c4ZG5WmEye56t928Yk3bOLai9bN6FpB8dSJExUm/Ouyzve1e+KTb9y8YtK1VkcjdPWP0Ds4Qtk045ZGZoK8vW4FvoHjlcQnJFX1iOu9GAmICBWRfCoi+fE/5M6+EXY0ttPRNxz/JprIdMUkjcXF8vIiHvqnV8WnQxNZlfDNPB21Va7SQxYC1F5sZkdj2+wZlYSV8R7+dVl+PPHJxBgMTNTn27TS/sbCIohReT0woKpjACKSAxSpar+qfi/U0S0i/N+sUhmVnsGZTX8Zi4fq0sJ4bZWZkJebw4rKoqyUut7tGpWHmtsZGRuPr3APk5aOfs5dPVmKJi4SmWBUDqWIwThtp/T5Nq20aqhhEeS34rc46sQeEbfNmAJB8uSnU6DLMDLhKD3MzFPxlK9jJQX0DY/xRGvGJM0Z0z0wQs/g6KR0Yo+66OTnak1QNJ5wftXMsjONYAQxKkVeqi6Auz35f8xIS/wXOs0ft1dC1jwVI5s49Udm5qnsP36S9r5hrnvFegB2zcLaF3+hrWQke66WTkd8ckVl0aTzKyP5lBbmZaVCq5GaIEalT0TO9XZE5GU42VXGFCgpzCNaUpD2j7t7YISC3BwK88KfVjCWDnXRYtpODjE4Mn0xRU+Y8vUvXcGmFeXsmAVNsVTpxB510WKO9U4UiWxJEJ/0IyKWVjwLBHl7/U/gx6468IPAD3EUi40pkm4VMDgxlfLi/AW5nsCYv3hrNlpnMAW2q6mdVZVOvfcLN8TYd6hzRkYqCKfqqKT2VBJFIls6ByZofiWyOsPfoDFzgqgU78FZL/I+4O+A01V1X9gDW4wklvxNZLpikoaRjlPxvOlNMIyPKw8daI+LlDbUVzM8Os4jrs5cWLR0DFBelJdyOrguiUhkS0d/yhiM1ydT1UhjZgSdZ3kxjqLwOTgS9n8V3pAWL/6Sv8noGZi+mKRhpKJuhp7Ks8d66ewfiVcSPW9dlLwcYUfIcZVU6cQeickvcfHJFDEYcL7YDYyM0ZahXo0xfYIISn4SR6DxqzhlhD8HvCnkcS1K6qoi8ZK/yZhugS7DSEdNWSGFeTnTln0/VUnUWUhZWpjH5rrK0DXFWjr60xqIuEika1RaM0yX+Y+ZsGR4BPFU3gq8CnhBVd8DbAZmnkC/BMmUVtwzOL0CXYaRDhFHTHG6sYTdze3URYsn6Gk11Md4orWb3sHUdeJngqrS2jmQdiorJ8cJvHsGwpveyzT95ZxrRiUsghiVAVfwcVREyoHjwPpwh7U4yZQnbzEVIyymu1bFiad0TBIp3VYfY2xcefhAR7aGOIETvUMMjY6n9TrAEVH1jEkqReMJ57uir5ZWHB5BjMpeV/L+G8A+nLolD4c6qkXKysripNISgKsXZjEVIxzqosXTepH+6WgP3QOn4ike566uojAvJ7QpsHQr4/3UTfBU+inMy6GmLPVESqQgj+rSQg61m6cSFmm/FrtKxDerahdOXZVfA+Wq+sSsjG6RUZCXw8qK4qRz2/3DY4yOq8VUjFCorZqemOLuZi+eMtGoFOXnsmVtVWhGJYjXAY7R8Z6rpWOAumgkY0p+XTR9FqYxM9J6Kq50/M98+wfNoMyM2hRz26b7ZYSJX0xxKuxubmdtLMKKislxiob6ap4+2kP7yaGsjNGPN05/9cZk+J+rpbM/XtMoUx8zKuERZPprt4ikLgJiTIlkekVgul9GuPjFFIMy5sVTUhQE8wqF7W7OflylpaOfZWWFFOWnr9viPdehjn4OdaRPQfb3OdI1yOhY8nLNxswIYlReCewSkSYReUJE/igi5q1Mk7qqCMd6JktmmO6XESan1qoE91T+dKSH3sHRSVNfHi9dVUFpYV68GmU2ybRGxcN7rj8d6aZ3cDTjdJnXZ2xcOdqdPLXfmBlBjMrlQD1wKfBG4A3uz4yIyGUi8qyINIrIR5McXyMi211j9YCI1PqO/VpEukTklwl9vi0iB0TkMfdzttsuIvIV915P+PXK5hPeN6vDXRP/uK2WihEmlZF8Sgpyp5RKu6vZMRapylPn5eZw/rpoKHEVrzhXJioj+ZQV5sXHkC6d2MPWqoRLEKOiKT5pEZFc4Gs4RmkTzkr8TQmn3QJ8V1XPAm4CbvYd+zzwzhSX/0dVPdv9POa2XQ5sdD/XAf8W4NlmHe8XOlHUrmeGpYQNIx0i4kqUTMGoNLWzvqaEZeWTFX89GjZUc6CtjyNd2UvRHRkb52h3eg0vDxGhNhrhsZYuIHO2GBC/rq1VCYcgRuUe4Jfuz+1AM/CrAP22Ao2q2qyqw8AdwBUJ52xyrwlwv/+4qm4HegPcx+MKHAOlqrobqBSRyTVF55j4NETCL3T3DEsJG0YmaqcggT86Ns6eg50pp748vLjKrix6K0e6BhhXZw1KEOqqihl1pY+CGJUVFUXk5khWCpcZkwkiKPlSVT3L/bkRx1j8IcC1VwEtvv1Wt83P48BV7vaVQJmIpP8tdviMO8X1RRHxktKD3A8RuU5E9orI3hMnTgS4VXZZVlZIQRLJDC/7y2pnG2HhrFXpDySm+OSRHk4Ojaac+vJ48fIyoiUFWdUBa0lTaCsZniGpKM4PNH2cl5vDiooim/4KiSkX7lDVR4Ag2WDJksUTf5s/DFwsIo8CFwOHgeSFuU9xA45q8nlAFPjIFO6Hqt6mqltUdUtNTU2GW2WfuLTEpOmvUcoK88jNMdl7IxxqqyL0DY/R2Z9ZWuWU3ld6o5KTI2yrj7GrqT1ryr+nJO8zx0eAeOwl6PlOH5PAD4uMcy0i8iHfbg5wLhDkK34rUOfbrwWO+E9Q1SPAW9z7lAJXqWraOqWqetTdHBKRb+EYpkD3my8ky5N3JFrMSzHCw3v5tnT0Ey0pSHvu7uZ2NiwrTbs63aOhPsY9TxzlYHs/66pLZjzOlo5+8nIk6dqYZHieSlDPxulTzP3Pzv5MxVIgyAR+mW97FCe28pMA/fYAG0VkHY4HcjXwDv8JIlINdLjaYjcAt2e6qIisUNWj7mr/NwNPuofuBq4XkTuA84FunwGaV9RFi+OBRQ+vQJdhhIU/62lzXWXK80bGxtlzsIOrzq1NeY6fhvpqAHY0tnFaeRHHewc51jMU/9ndP5w5s8fH7545zsrK4sBee9yoBIzBgGOATvQOcct9z5K4AD9HhKu31gU2asZEMhoVVf3UdC6sqqMicj1wH5AL3K6qT4nITcBeVb0buAS4WUQU+D3wfq+/W2XyJUCpiLQC16rqfcAPRKQGZ7rrMeBv3S73Aq8HGoF+4D3TGfdsUFcVoXtghG6f1lf3wAjlRRakN8IjqJjiE63d9A+PpVz0mMjaWISVFUV88u6n+PjPnpx0XCT53HQ63ralLvNJLqujEV68vCxj/MfPy9Y62mVff6Bx0rFxhZNDo3ziDYnJqkYQgkx//Qb4c1f/CxGpAu5Q1ddl6quq9+K87P1tN/q27wTuTNH35SnaL03RrviM0nzGL79dsaoCcFKKg6RQGsZ0KSvKpzKSnzGW4Ol9nb8uGui6IsKNb9zE7uYOlpUXsqysiOXuz2VlhVRGwi2RXZSfy30ffMWU+jTUV/Pspy9Peuzq23bF/w2MqRPkq3GNZ1AAVLVTRJaFOKZFj2c8Wjv7OdNnVGz6ywgbJ56X3lPZ2dTGS04rI1YavGzSZWeu4LIz510G/7TYtr6aL21/jq7+YSoj6WNPxmSCZH+Nichqb0dE1hBg8aORmmTiflagy5gN6qLFk9ZI+RkcGWPvwc54nGQpsq0+hio8FFKtmMVOEKPyMeAPIvI9EfkeTuzjhnCHtbipiORTVpQXzwAbHRvn5NCoSbQYoVNbFaG1a4Dx8eTfCx891MXQ6Hh8UeNSZHNdBYV5OTYFNk2CBOp/7epoXYATb/ugqmZfQW6JUVcViUu19A56YpIWqDfCpa6qmOHRcU6cHGJ5EvmVnU1t5OYI568PFk9ZjBTmObVisqkSsJTI6KmIyJXAiKr+UlV/gVNW+M3hD21xUxc9tQDSZO+N2aI2g+7VzqZ2XrqqYskrO2xbH+OZF3rp7Bue66EsOIJMf33SvyDRDdp/MrwhLQ3qqiK0dg44ZYStQJcxS8TjeUkkSk4OjfJ4S9eSnvry8JQEHjpg3spUCWJUkp1j8zQzpC4aYWh0nBO9Q+apGLNGfK1KEjHFPQc6GB1XLtywdIP0HmfVVlKcn2tTYNMgiFHZKyJfEJF6EVkvIl8E9oU9sMXOat/qZivQZcwWRfm51JQVJvVUdja1UZCbw8vWVM3ByOYXBXk5bFlbFUpVy8VOEKPy/wHDwA+BHwODwN+FOailQLy8a8eAFegyZpW6quKksu87m9o5d01lxhK+S4UL1sd49lgv7SeH5nooC4og0vd9qvpRV9n3ZcCngD8Lf2iLm9qqU8W6LKZizCZ10cmCpp19w/zpaA8XLuH1KYl4MjXmrUyNQNL3IpIrIpeLyHeBg8DbQx3VEiA+DdHRT/fACPm5QlH+lCsRGMaUqa0q5mj3IKNj4/G23c3tqELDBgvSe7x0VQUlBbm2XmWKpA24i8grcJSF/wx4GLgQWK+qVoggC9RVFdPS2U9BXg4VxeHqIxmGR11VhLFx5Wj3YFyHbmdTO5GCXM6qTa1evNTIz81hy9oou8yoTImUX41dZeB/AXYAm1T1KmDADEr2qItG4jEVi6cYs4VfAt9jZ1MbW9dFyc81b9nPtvoYjcdPcrx3cK6HsmBI9xv0E5xyvG8H3igiJZjmV1apq4pwtHuAjr5hSyc2Zo3EtOIXugdpOtFn8ZQkeHL6D1lcJTApjYqq/j2wFvgC8ErgOaBGRN7mVmk0ZsjqaIRxhWdf6DWjYswaKyuLyRFHJRtgV7OjuhS0fspS4oyV5ZQW5tkU2BRI6+uqw+9U9W9wDMw7cKotHgxycRG5TESeFZFGEflokuNrRGS7iDwhIg+ISK3v2K9FpEtEfpnQ5wfuNZ8UkdtFJN9tv0REukXkMfdzY+L95hu1blpxe9+wZX4Zs0Z+bg4rKorjEvg7G9upjOSzaUX5HI9s/pGXm8PWdVF22yLIwASeQFXVEVX9haq+g4m14JMiIrnA14DLgU3ANSKSWErtFuC7qnoWcBNws+/Y54F3Jrn0D3AqQr4UKAbe6zv2oKqe7X5uCvhoc4a/prZVfTRmk9oqR3tOVdnZ1M629TFyApbvXWpsWx+jua2PYz0WVwnCtKJyqpq+yo/DVqBRVZtVdRi4A7gi4ZxNwHZ3+37/cVXdDvQmufe9rgelOBlpwQppz0NWVBTF63Cbp2LMJrVVzlqVQx39HO4aML2vNJxar2LeShDCTPVYBbT49lvdNj+PA1e521cCZSIS6LfbnfZ6J/BrX/M2EXlcRH4lImek6HediOwVkb0nTpwIcqvQyMvNYWWlIz9uMRVjNqmLFnOsZ4gHnnX+BrZZkD4lp68op7woz4xKQAIbFTf7ayok86UTs8c+DFwsIo8CFwOHgdGA1/868HtVfdDdfwRYo6qbga8CP0vWSVVvc9UBttTU1AS8VXh4U2DmqRizifd79+N9LSwvL6S+Zqp/3kuH3Bxh67qYiUsGJEg9lQYR+RPwtLu/WUS+HuDarUyMvdQCR/wnqOoRVX2Lqp6DU2ESv8x+mjF9EqgBPuS7Vo+qnnS37wXyRWTef/3yhCVtnYoxm3hrVZ483ENDfbUtvM3AtvoYB9v7OdodZOZ/aRPEU/ki8DqgHUBVHwdeEaDfHmCjiKwTkQLgauBu/wkiUi0i3hhuAG7PdFERea87nmtUddzXfpq4fxkishXn2eb9Vwvvj7vcqj4as4i3VgUslTgIF7iVMG0KLDOB3mSq2pLwTWYsQJ9REbkeuA/IBW5X1adE5CZgr6reDVwC3CwiCvweeL/XX0QexMnyKnVX91+rqvcB/w48D+xyx3SXm+n1VuB9IjIKDABXu8H8ec2amGNUqiIFczwSYymxvLyI/FxhZEwtSB+A008rpzKSz4/2tHJyKOPrLxBnrapgc11wWZyHD3SwcVkpVSXz+10RxKi0iEgDoK7H8QHcqbBMuNNQ9ya03ejbvhO4M0Xfl6doTzpmVb0VuDXIuOYTrzvjNL56zTmcsdLWCBizR26OsKqyGOWUYraRmpwc4dKXLOOuRw5nbSHkaeVF7Lrh0kBTj139w1zzjd2884I1/PObkuYgzRuCGJW/Bb6Mk7nVCvxffB6FMTPyc3N44+aVcz0MYwnyvkvqrXbKFLjlrZu54fLTs3Ktnz92mE/f8zTNbX3U12QWKNnd3M7YuLKjsS0r9w+TjEZFVduAv5iFsRiGMYu8/bzVcz2EBUVOjlBTVpiVa7369OV8+p6n2dnUHsio7HQzz/a74pbLyoqyMo4wyGhUROQrSZq7ceIiP8/+kAzDMBY3a2IRVlYUsbOxjXdesCbj+Tsa21hRUcTR7kF2NbVzxdmJS/7mD0Gyv4qAs4H97ucsIApcKyJfCnFshmEYixIRoWFDNbua2xkfT59PdKzHUZH+q21rKS/KY2fj/M5AC2JUNgCXqupXVfWrwKuB03FWwL82zMEZhmEsVhrqY3T1j/D0Cz1pz/MWXb58YzUXrI+xs3l+x1WCGJVVgH+5bQmwUlXHgKFQRmUYhrHI8dYHZfI8djS2UVGcz+kryrlwQzUtHQO0dMzfWolBjMrngMdE5Fsi8m3gUeAWV7blt2EOzjAMY7GyoqKY9dUl7GxK7Xn4VaRzcyS+pihdn7kmo1FR1f8AGnC0tH4GXKSq31TVPlX9x7AHaBiGsVhp2BDj4QMdjIyNJz3e0jHgqEhvcIzJhmWl1JQVxrPB5iNBBSUHgaNAB7BBRILItBiGYRhpaKivpm94jCdak0seeh6J56GION7KzqZ25qtgSBBByffiSKjcB3zK/fnP4Q7LMAxj8XPBei+uknw6a0dTO8vKCiesZWmoj3Gid4jG4ydnZYxTJYin8vfAecDzqvpK4BxgbguRGIZhLAKiJQVsWlGedDpLVdnV1EZDfWyClEuDW/tmvk6BBTEqg6o6CCAihar6DPDicIdlGIaxNGioj7HvUCeDIxOFKvcfP0nbyeG4EfGoi0aoixbPW8mWIEalVUQqcYL0vxGRn5NQF8UwDMOYHg0bYgyPjrPv+c4J7Z7R8IL0E/qsr47rgc03gmR/XamqXar6z8AngP8A3hz2wAzDMJYCW9c56cKJacI7m9pZHY0kVZFu2BCjZ3CUPx1Jv3ByLkhrVEQkR0Se9PZV9b9V9W5VHQ5/aIZhGIuf0sI8NtdWTIiRjI0ru5vbU9a68RZO7piH61XSGhW3suLjImJypoZhGCHRUF/NE63d9A6OAPDk4W56B0dTVuVcVlbExmWl8zJYHySmsgJ4SkS2i8jd3ifIxUXkMhF5VkQaReSjSY6vca/7hIg8ICK1vmO/FpEuEfllQp91IvKQiOwXkR+6hcMQkUJ3v9E9vjbIGA3DMOaahg0xxsaVhw90AKcyuxKD9BP61MfYc6CD4dHkCyfniiBG5VPAG4CbgH/1fdIiIrnA14DLgU3ANSKyKeG0W4DvqupZ7vVv9h37PPDOJJf+LPBFVd0IdALXuu3XAp2qugH4onueYRjGvOfc1VUU5OXEjcnOpjZetLw0bf2Whg3VDIyM8Xhr12wNMxBBAvX/DRwE8t3tPcAjAa69FWhU1WY3BnMHcEXCOZuA7e72/f7jqrod6PWfLE6y9qWcKkH8HU4lDVzh7uMef5UEqdNpGIYxxxTl57JlTRU7GtsYGh1jz8GOtF4KwAXrYogw71KLg6yo/xucl/T/cZtW4aQXZ2IV0OLbb3Xb/DwOXOVuXwmUiUjySUSHGNClqqNJrhm/n3u82z0/8XmuE5G9IrL3xAlbw2kYxvzgwg3VPPNCL797+jiDI+Mpg/QeFZF8zlxZMe/iKkGmv94PXAj0AKjqfmBZgH7JvITEpOoPAxeLyKPAxcBhYHRSr2DXDHI/VPU2Vd2iqltqamrS3MowDGP28ILyX/ztc+QInL8+vVEBJxbz6KFOBobHMp47WwQxKkP+FGIRySPJyzoJrUCdb7+WhEWTqnpEVd+iqucAH3PbkiurObQBle4YEq8Zv597vAJHANMwDGPec9aqCkoL83ju2EnOXFVBRXF+xj4N9dWMjCl7Ds6fV10Qo/LfIvJPQLGIvAb4MfCLAP32ABvdbK0C4GpgQtaYiFSLiDeGG4Db011QHVnO+4G3uk3vAn7ubt/t7uMe/53OVxlPwzCMBPJyczh/XRRIn/Xl57y1VeTnyryaAsvLfAofxcms+iPwP4B7gW9m6qSqoyJyPY6qcS5wu6o+JSI3AXtV9W7gEuBmEVEcJeT3e/1F5EHgJUCpiLQC16rqfcBHgDtE5NM4BcP+w+3yH8D3RKQRx0O5OsCzGYZhzBu21cfY/szxjPEUj0hBHufUVfHNB5v5z4een3S8rCifu/6ugeXlRdkeakok05d5EbkSuFdVF13p4C1btujevXvnehiGYRgA9AyO8KM9Lby7YS15ucHKXe17vlx8XQAADO1JREFUvpNfPD5ZjnFwZIw79rTw2ateytvPy+76dRHZp6pbkh0L4qm8CfiSiPweJy34Pl/2lWEYhpElyovyee/L10+pz8vWVPGyNVWT2lWV3z59jF1N7Vk3KukIsk7lPcAGnFjKO4AmEck4/WUYhmHMHSLC+etj7G7umNUqkYH8K1UdAX6F46nsY/IiRsMwDGOesW19jBd6BjnY3j9r9wyy+PEyEfk20IiTVfVNHD0wwzAMYx7jrX3ZNYvZYUE8lXfjrKB/kaq+S1XvtZiKYRjG/Gd9dQk1ZYXsbp5HRkVVr1bVn3nZXyJyoYh8LfyhGYZhGDNBRNi2Psau5vZZi6sEiqmIyNki8jkROQh8Gngm1FEZhmEYWWFbfYwTvUM0neiblfulTCkWkRfhLCC8BmgHfoizruWVszIywzAMY8Zc4GqI7W5uZ8Oy0tDvl85TeQZ4FfBGVb1IVb8KzB/VMsMwDCMja2MRTisvYtcsxVXSGZWrgBeA+0XkGyLyKpIrARuGYRjzFBFhW32Mh2YprpLSqKjqT1X17Tj6Ww8AHwSWi8i/ichrQx+ZYRiGkRUuWB+l7eQwjcdPhn6vINlffar6A1V9A47U/GM4IpOGYRjGAmDbekf1eDamwIIplrmoaoeq/h9VvTSsARmGYRjZpS5azKrK4llZrzIlo2IYhmEsPBwdsCi7mzsYHw83rmJGxTAMYwmwbX2Mjr5hnjveG+p9QjUqrm7YsyLSKCKT4jAiskZEtovIEyLygIjU+o69S0T2u593uW1lIvKY79MmIl9yj71bRE74jr03zGczDMNYSMTXq4SsAxaaURGRXOBrwOXAJuAaEdmUcNotwHdV9SzgJuBmt28U+CRwPrAV+KSIVKlqr6qe7X2A54G7fNf7oe+4yfMbhmG41EUj1FYVhx6sD9NT2Qo0qmqzqg7jyOYnSuZvAra72/f7jr8O+I2bGNAJ/Aa4zN9RRDYCy4AHQxq/YRjGomLb+hgPHQg3rhKmUVkFtPj2W902P4/jLLIEuBIoE5FYwL7X4Hgm/n+dq9yptDtFpC7ZoETkOhHZKyJ7T5w4MbUnMgzDWMBsq4/R1T/CMy+EF1cJ06gkW32faB4/DFwsIo8CFwOHgdGAfa8G/su3/wtgrTuV9lvgO8kGpaq3qeoWVd1SU1OT+SkMwzAWCV5cJcwpsDCNSivg9xZqgSP+E1T1iKq+RVXPAT7mtnVn6isim4E8Vd3nu1a7J88PfAN4WRafxTAMY8GzsrKYNbFIqEW7wjQqe4CNIrJORApwPIu7/SeISLWIeGO4Abjd3b4PeK2IVIlIFfBat83jGiZ6KYiIvxrlm4Cns/YkhmEYi4Rt62M8fKCdsZDiKqEZFbc65PU4xuBp4Eeq+pSI3CQib3JPuwR4VkSeA5YDn3H7dgD/C8cw7QFucts83kaCUQE+ICJPicjjwAdwKlYahmEYPrbVx+gZHOXpoz2hXF9mqxrYfGTLli26d+/euR6GYRjGrHGsZ5Dz//d2Pvb60/mbV6yf1jVEZJ+qbkl2zFbUG4ZhLCGWlxdxxdkrWVZeGMr1U1Z+NAzDMBYnX776nNCubZ6KYRiGkTXMqBiGYRhZw4yKYRiGkTXMqBiGYRhZw4yKYRiGkTXMqBiGYRhZw4yKYRiGkTXMqBiGYRhZY0nLtIjICZzqkemoBtpmYTjzkaX87LC0n38pPzss7ecP8uxrVDVp7ZAlbVSCICJ7U2ncLHaW8rPD0n7+pfzssLSff6bPbtNfhmEYRtYwo2IYhmFkDTMqmbltrgcwhyzlZ4el/fxL+dlhaT//jJ7dYiqGYRhG1jBPxTAMw8gaZlQMwzCMrGFGJQ0icpmIPCsijSLy0bkeT5iIyO0iclxEnvS1RUXkNyKy3/1ZNZdjDAsRqROR+0XkaRF5SkT+3m1fKs9fJCIPi8jj7vN/ym1fJyIPuc//QxEpmOuxhoWI5IrIoyLyS3d/KT37QRH5o4g8JiJ73bZp/+6bUUmBiOQCXwMuBzYB14jIprkdVah8G7gsoe2jwHZV3Qhsd/cXI6PAP6jq6cAFwPvd/+ul8vxDwKWquhk4G7hMRC4APgt80X3+TuDaORxj2Pw98LRvfyk9O8ArVfVs3/qUaf/um1FJzVagUVWbVXUYuAO4Yo7HFBqq+nugI6H5CuA77vZ3gDfP6qBmCVU9qqqPuNu9OC+XVSyd51dVPenu5rsfBS4F7nTbF+3zi0gt/6+9uw+RqzrjOP79maTVNmKoL6GtyjbWJjXiC2JAEjRq6B8aVMSgojW00heDBoVQUNpUhIBWbIOtqDS1VYwvq61VUEws3YjJH0kaGxJT84JJ0BAxkRJF0S1xf/3jPKvXYd+cnXXInefzz8w9c+bc57B359xz78xz4GJgWWyLDun7EJo+9nNQGdy3gbcq23uirJNMtv02lA9e4Lg2xzPmJHUBZwJr6aD+x+WfjcA+4CXgDeCA7YNRpc7H/1LgF0BfbB9N5/QdygnESkkbJP00ypo+9sePQYB1oQHK8vvXNSZpIvBX4Gbb75cT1s5g+xPgDEmTgGeA7w9U7cuNauxJmgvss71B0uz+4gGq1q7vFTNt75V0HPCSpK2jaSxnKoPbA5xQ2T4e2NumWNrlHUnfBIjHfW2OZ8xImkAZUJbb/lsUd0z/+9k+AKyi3FuaJKn/xLOux/9M4BJJuymXuC+gzFw6oe8A2N4bj/soJxQzGMWxn4PK4NYDJ8e3QL4CXAU81+aYvmzPAfPj+Xzg2TbGMmbiGvqfgNdt/7byUqf0/9iYoSDpCGAO5b5SD3BFVKtl/23favt4212U//F/2r6GDug7gKSvSzqy/znwA+A1RnHs5y/qhyDpIspZyzjgIdtL2hzSmJH0ODCbkvb6HeDXwN+BbuBE4E1gnu3Gm/mHPEmzgFeAzXx2Xf02yn2VTuj/aZSbseMoJ5rdtu+QNIVy9v4N4N/AtbZ72xfp2IrLX4tsz+2Uvkc/n4nN8cBjtpdIOpomj/0cVFJKKbVMXv5KKaXUMjmopJRSapkcVFJKKbVMDioppZRaJgeVlFJKLZODSqoNSZZ0T2V7kaTbW9T2XyRdMXzNUe9nXmRL7mlBW3dImjNMndslLRqgvKuasTqlkcpBJdVJL3C5pGPaHUhVZLweqeuBBbbPH+1+bS+2/Y/RttOML9jnVCM5qKQ6OUhZX/uWxhcaZxqSPojH2ZJeltQtabukOyVdE+uLbJZ0UqWZOZJeiXpz4/3jJN0tab2kTZJ+Vmm3R9JjlB9VNsZzdbT/mqS7omwxMAt4QNLdDfVnS1ol6WlJWyUtj0wASDor+rBB0opKeo1P+yzponjfakn3KtYNCadE2zslLayUj5f0cPTraUlfi7YuVFl7ZLPKOjxfjfLdkhZLWg3Mk7RQ0n/i/U+M4O+XaiATSqa6uQ/YJOk3X+A9p1MSKP4X2Akssz1DZbGum4Cbo14XcB5wEtAj6bvAdcB7ts+OD9c1klZG/RnAqbZ3VXcm6VuU9TrOoqzVsVLSZfEr9gsov+r+1wBxnglMp+ShWgPMlLQW+D1wqe39kq4ElgA/ruzvcOBB4FzbuyJ7QtU04HzgSGCbpPujfCpwve01kh4CFkj6A2XtnQttb5f0CHADJfMEwMe2Z8V+9wLfsd3bnwYm1V/OVFKt2H4feARYOFzdivWxpkovJeV7/6CwmTKQ9Ou23Wd7B2XwmUbJlXSdStr4tZS06SdH/XWNA0o4G1hle3+kV18OnDuCONfZ3mO7D9gYsU0FTqVkl90I/JKSALFqGrCzEkvjoPK87V7b71ISB06O8rdsr4nnj1JmUVOBXba3R/nDDbE/WXm+CVgu6VrKLDJ1gJyppDpaCrwK/LlSdpA4iYrLRtXlYas5nfoq2318/n+kMaeRKWnSb7K9ovpC5JH6cJD4ms2pX43zk4hNwBbb5wzxvuH2N1C7MHh/h1Lt88WUAecS4FeSplfWKEk1lTOVVDuR+K6bzy8Bu5tyuQnKqnYTmmh6nqTD4j7LFGAbsAK4QSV1PpK+F9leh7IWOE/SMXFD+2rg5SbiIWI4VtI5sf8JkqY31NkKTFFZgAzgyhG2fWJ/uxHj6mirKy79AfxwoNglHQacYLuHsgDWJGDiCPebDmE5U0l1dQ9wY2X7j8CzktZR1twebBYxlG2UD9DJwM9tfyxpGeUy1KsxA9rPMEuv2n5b0q2U9OoCXrDdVGp12/+Lm/H3SjqK8j+9FNhSqfORpAXAi5LeBdaNsPnXgfmSHgR2APdHn38EPKWy3sh64IEB3jsOeDRiEmW99wPN9DEdWjJLcUodQNJE2x/EwHcfsMP279odV6qfvPyVUmf4SdzI3wIcRfk2WEotlzOVlFJKLZMzlZRSSi2Tg0pKKaWWyUElpZRSy+SgklJKqWVyUEkppdQy/wdh7yC54Gg5mQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualze performance across neighbors N values\n",
    "test_scores = grid_search.cv_results_['mean_test_score']\n",
    "plt.plot(param_grid['n_neighbors'], test_scores)\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.ylabel('Average Accuracy across CV folds')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing Data\n",
    "Because KNN uses a distance based metric to compute similarity, it's important to **normalize** each column to the same scale before running the algorithm. Note, some rule based estimators (like decision trees) aren't sensitive to feature scale (and don't need to be normalized). For example, we can use a `MinMaxScaler` that subracts the minimum, and divides by the difference between the minimum and the maximum of each column.\n",
    "\n",
    "In order to not **leak information** from out test data into our training data, it's important to normalize our data **after** splitting. We'll worry about integrating this into our process after experimenting with it in the section below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually scale (pre-process) our *training features* (not the outcome!) data\n",
    "train_features_scaled = (train_features - train_features.min(axis=0)) / (train_features.max(axis=0) - train_features.min(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, we could use a built in Scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "train_scaled_alt = scaler.fit(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a knn classifier with the scaled training data\n",
    "scaled_fit = knn_clf.fit(train_features_scaled, train_outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate predictions using *scaled test data*\n",
    "test_features_scaled = scaler.fit_transform(test_features)\n",
    "accuracy_score(scaled_fit.predict(test_features_scaled), test_outcome)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Pipelines\n",
    "Our final challenge is determining how to integrate the data scaling into our cross validation process. For **each set** of possible model parameters, we need to:\n",
    "\n",
    "- **Split** our (training) data into training and validation sets\n",
    "- **Normalize**/scale each training set\n",
    "- **Assess** the model on all validation sets\n",
    "\n",
    "\n",
    "While we could write the iterators to do this ourselves, this is a problem that is already solved using **Pipelines**. The `GridSearchCV` class is structured to take as an argument a _pipeline_ object, which includes each transformation or calculation you want to perform on your data. For example\n",
    "\n",
    "```python\n",
    "# Define scaler, classifier, and pipeline to use\n",
    "scaler = MinMaxScaler()\n",
    "knn_clf = KNeighborsClassifier()\n",
    "pipe = make_pipeline(scaler, knn_clf)\n",
    "\n",
    "# Define grid for pipeline (indicates which arguments are for which classes)\n",
    "param_grid = {'kneighborsclassifier__n_neighbors': [1, 3, 5, 10]}\n",
    "\n",
    "# Search through and perform cross validation\n",
    "grid = GridSearchCV(pipe, param_grid)\n",
    "```\n",
    "\n",
    "Our final process will be:\n",
    "\n",
    "- **Import** your model\n",
    "- **Create** your model\n",
    "- **Split** data into training and testing data\n",
    "- **Create** your normalization (scaling) function\n",
    "- **Define** a **pipeline** that will implement your pre-processing and your model\n",
    "- **Fit** and **assess** models using `grid_search` to fit multiple models using **different parameters** on different _folds_ of validation data</span>\n",
    "- **Assess** performance of the (best) model on your **test** data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pipeline, and define your pipeline that will\n",
    "# - Transform you data using a MinMaxScaler\n",
    "# - Fit a KNN classifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Define scaler, classifier, and pipeline to use\n",
    "scaler = MinMaxScaler()\n",
    "knn_clf = KNeighborsClassifier()\n",
    "pipe = make_pipeline(scaler, knn_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('minmaxscaler',\n",
       "                                        MinMaxScaler(copy=True,\n",
       "                                                     feature_range=(0, 1))),\n",
       "                                       ('kneighborsclassifier',\n",
       "                                        KNeighborsClassifier(algorithm='auto',\n",
       "                                                             leaf_size=30,\n",
       "                                                             metric='minkowski',\n",
       "                                                             metric_params=None,\n",
       "                                                             n_jobs=None,\n",
       "                                                             n_neighbors=5, p=2,\n",
       "                                                             weights='uniform'))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'kneighborsclassifier__n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
       "       35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pass your pipeline to a grid search, specifying a set of neighbors to assess\n",
    "\n",
    "# Define grid for pipeline (indicates which arguments are for which classes)\n",
    "param_grid = {'kneighborsclassifier__n_neighbors': np.arange(1, 50)}\n",
    "\n",
    "# Search through and perform cross validation\n",
    "grid = GridSearchCV(pipe, param_grid)\n",
    "grid.fit(train_features, train_outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kneighborsclassifier__n_neighbors': 8}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9766081871345029"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.score(test_features, test_outcome)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
